{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1710,
     "status": "ok",
     "timestamp": 1686659886524,
     "user": {
      "displayName": "ELSA",
      "userId": "12819283556995342183"
     },
     "user_tz": -480
    },
    "id": "ZN0LJEs8wPSF"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris=datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 509,
     "status": "ok",
     "timestamp": 1686660540991,
     "user": {
      "displayName": "ELSA",
      "userId": "12819283556995342183"
     },
     "user_tz": -480
    },
    "id": "JZntKPtNwPSK"
   },
   "outputs": [],
   "source": [
    "iris_x=iris.data\n",
    "iris_y=iris.target\n",
    "\n",
    "# import pandas as pd\n",
    "# iris_x = pd.DataFrame(iris.data)\n",
    "# iris_x=iris_x.iloc[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#permutation接收一個數作為參數(150),產生一個0-149的一維陣列並隨機打亂\n",
    "indices = np.random.permutation(len(iris_x))\n",
    "\n",
    "iris_x_train = iris_x[indices[:-10]]#隨機選取140個樣本\n",
    "iris_y_train = iris_y[indices[:-10]]#取得140個樣本的標籤\n",
    "\n",
    "iris_x_test = iris_x[indices[-10:]]#測試資料集\n",
    "iris_y_test = iris_y[indices[-10:]]#測試資料集的標籤\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1686660550623,
     "user": {
      "displayName": "ELSA",
      "userId": "12819283556995342183"
     },
     "user_tz": -480
    },
    "id": "j_3cC-AQwPSK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInit signature:\u001b[39m\n",
      "KNeighborsClassifier(\n",
      "    n_neighbors=\u001b[32m5\u001b[39m,\n",
      "    *,\n",
      "    weights=\u001b[33m'uniform'\u001b[39m,\n",
      "    algorithm=\u001b[33m'auto'\u001b[39m,\n",
      "    leaf_size=\u001b[32m30\u001b[39m,\n",
      "    p=\u001b[32m2\u001b[39m,\n",
      "    metric=\u001b[33m'minkowski'\u001b[39m,\n",
      "    metric_params=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    n_jobs=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      ")\n",
      "\u001b[31mDocstring:\u001b[39m     \n",
      "Classifier implementing the k-nearest neighbors vote.\n",
      "\n",
      "Read more in the :ref:`User Guide <classification>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "n_neighbors : int, default=5\n",
      "    Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
      "\n",
      "weights : {'uniform', 'distance'}, callable or None, default='uniform'\n",
      "    Weight function used in prediction.  Possible values:\n",
      "\n",
      "    - 'uniform' : uniform weights.  All points in each neighborhood\n",
      "      are weighted equally.\n",
      "    - 'distance' : weight points by the inverse of their distance.\n",
      "      in this case, closer neighbors of a query point will have a\n",
      "      greater influence than neighbors which are further away.\n",
      "    - [callable] : a user-defined function which accepts an\n",
      "      array of distances, and returns an array of the same shape\n",
      "      containing the weights.\n",
      "\n",
      "    Refer to the example entitled\n",
      "    :ref:`sphx_glr_auto_examples_neighbors_plot_classification.py`\n",
      "    showing the impact of the `weights` parameter on the decision\n",
      "    boundary.\n",
      "\n",
      "algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, default='auto'\n",
      "    Algorithm used to compute the nearest neighbors:\n",
      "\n",
      "    - 'ball_tree' will use :class:`BallTree`\n",
      "    - 'kd_tree' will use :class:`KDTree`\n",
      "    - 'brute' will use a brute-force search.\n",
      "    - 'auto' will attempt to decide the most appropriate algorithm\n",
      "      based on the values passed to :meth:`fit` method.\n",
      "\n",
      "    Note: fitting on sparse input will override the setting of\n",
      "    this parameter, using brute force.\n",
      "\n",
      "leaf_size : int, default=30\n",
      "    Leaf size passed to BallTree or KDTree.  This can affect the\n",
      "    speed of the construction and query, as well as the memory\n",
      "    required to store the tree.  The optimal value depends on the\n",
      "    nature of the problem.\n",
      "\n",
      "p : float, default=2\n",
      "    Power parameter for the Minkowski metric. When p = 1, this is equivalent\n",
      "    to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2.\n",
      "    For arbitrary p, minkowski_distance (l_p) is used. This parameter is expected\n",
      "    to be positive.\n",
      "\n",
      "metric : str or callable, default='minkowski'\n",
      "    Metric to use for distance computation. Default is \"minkowski\", which\n",
      "    results in the standard Euclidean distance when p = 2. See the\n",
      "    documentation of `scipy.spatial.distance\n",
      "    <https://docs.scipy.org/doc/scipy/reference/spatial.distance.html>`_ and\n",
      "    the metrics listed in\n",
      "    :class:`~sklearn.metrics.pairwise.distance_metrics` for valid metric\n",
      "    values.\n",
      "\n",
      "    If metric is \"precomputed\", X is assumed to be a distance matrix and\n",
      "    must be square during fit. X may be a :term:`sparse graph`, in which\n",
      "    case only \"nonzero\" elements may be considered neighbors.\n",
      "\n",
      "    If metric is a callable function, it takes two arrays representing 1D\n",
      "    vectors as inputs and must return one value indicating the distance\n",
      "    between those vectors. This works for Scipy's metrics, but is less\n",
      "    efficient than passing the metric name as a string.\n",
      "\n",
      "metric_params : dict, default=None\n",
      "    Additional keyword arguments for the metric function.\n",
      "\n",
      "n_jobs : int, default=None\n",
      "    The number of parallel jobs to run for neighbors search.\n",
      "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "    for more details.\n",
      "    Doesn't affect :meth:`fit` method.\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "classes_ : array of shape (n_classes,)\n",
      "    Class labels known to the classifier\n",
      "\n",
      "effective_metric_ : str or callble\n",
      "    The distance metric used. It will be same as the `metric` parameter\n",
      "    or a synonym of it, e.g. 'euclidean' if the `metric` parameter set to\n",
      "    'minkowski' and `p` parameter set to 2.\n",
      "\n",
      "effective_metric_params_ : dict\n",
      "    Additional keyword arguments for the metric function. For most metrics\n",
      "    will be same with `metric_params` parameter, but may also contain the\n",
      "    `p` parameter value if the `effective_metric_` attribute is set to\n",
      "    'minkowski'.\n",
      "\n",
      "n_features_in_ : int\n",
      "    Number of features seen during :term:`fit`.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "\n",
      "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "    Names of features seen during :term:`fit`. Defined only when `X`\n",
      "    has feature names that are all strings.\n",
      "\n",
      "    .. versionadded:: 1.0\n",
      "\n",
      "n_samples_fit_ : int\n",
      "    Number of samples in the fitted data.\n",
      "\n",
      "outputs_2d_ : bool\n",
      "    False when `y`'s shape is (n_samples, ) or (n_samples, 1) during fit\n",
      "    otherwise True.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "RadiusNeighborsClassifier: Classifier based on neighbors within a fixed radius.\n",
      "KNeighborsRegressor: Regression based on k-nearest neighbors.\n",
      "RadiusNeighborsRegressor: Regression based on neighbors within a fixed radius.\n",
      "NearestNeighbors: Unsupervised learner for implementing neighbor searches.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "See :ref:`Nearest Neighbors <neighbors>` in the online documentation\n",
      "for a discussion of the choice of ``algorithm`` and ``leaf_size``.\n",
      "\n",
      ".. warning::\n",
      "\n",
      "   Regarding the Nearest Neighbors algorithms, if it is found that two\n",
      "   neighbors, neighbor `k+1` and `k`, have identical distances\n",
      "   but different labels, the results will depend on the ordering of the\n",
      "   training data.\n",
      "\n",
      "https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> X = [[0], [1], [2], [3]]\n",
      ">>> y = [0, 0, 1, 1]\n",
      ">>> from sklearn.neighbors import KNeighborsClassifier\n",
      ">>> neigh = KNeighborsClassifier(n_neighbors=3)\n",
      ">>> neigh.fit(X, y)\n",
      "KNeighborsClassifier(...)\n",
      ">>> print(neigh.predict([[1.1]]))\n",
      "[0]\n",
      ">>> print(neigh.predict_proba([[0.9]]))\n",
      "[[0.666... 0.333...]]\n",
      "\u001b[31mFile:\u001b[39m           d:\\_py2_20250426六\\mypy312\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\n",
      "\u001b[31mType:\u001b[39m           ABCMeta\n",
      "\u001b[31mSubclasses:\u001b[39m     "
     ]
    }
   ],
   "source": [
    "KNeighborsClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 373,
     "status": "ok",
     "timestamp": 1686661041173,
     "user": {
      "displayName": "ELSA",
      "userId": "12819283556995342183"
     },
     "user_tz": -480
    },
    "id": "cM-ys6KCwPSL",
    "outputId": "22851ded-eecc-463f-de42-30b72a818205"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris_y_predict =  [1 2 1 0 0 0 2 1 2 0]\n",
      "iris_y_test =  [1 1 1 0 0 0 2 1 2 0]\n",
      "score: 0.9\n",
      "probility: [[0.         1.         0.        ]\n",
      " [0.         0.29791809 0.70208191]\n",
      " [0.         1.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         0.         1.        ]\n",
      " [1.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#預設參數：n_neighbors=5， p=2(歐氏距離)/(p=1:曼哈頓距離)\n",
    "knn = KNeighborsClassifier(p=2, n_neighbors=5, weights='distance') # k=5\n",
    "\n",
    "knn.fit(iris_x_train, iris_y_train)\n",
    "\n",
    "iris_y_predict = knn.predict(iris_x_test)\n",
    "probility=knn.predict_proba(iris_x_test)\n",
    "\n",
    "neighborpoint=knn.kneighbors(iris_x_test,5,False)#\n",
    "score=knn.score(iris_x_test,iris_y_test,sample_weight=None)\n",
    "\n",
    "print('iris_y_predict = ',iris_y_predict)\n",
    "print('iris_y_test = ', iris_y_test)\n",
    "print('score:',score)\n",
    "print('probility:',probility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 488,
     "status": "ok",
     "timestamp": 1686661272924,
     "user": {
      "displayName": "ELSA",
      "userId": "12819283556995342183"
     },
     "user_tz": -480
    },
    "id": "p3_XjI1205KG",
    "outputId": "6e7c52b5-9999-4c81-cf9d-9588384ab85f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n",
      "測試點最近的鄰居index: [[ 71  81 127  63  38]\n",
      " [119  33  76  60  52]\n",
      " [ 79 132   1  13  27]\n",
      " [ 44 113 107  68  32]\n",
      " [122  87  99  97  68]\n",
      " [106  93  61  82 134]\n",
      " [ 46  30  86  70  34]\n",
      " [ 39 128 127  50  63]\n",
      " [116 104  80  51 121]\n",
      " [ 75  41  96  78 123]]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', score)\n",
    "print('測試點最近的鄰居index:', neighborpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0LC7N2MpwPSM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mypy312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
